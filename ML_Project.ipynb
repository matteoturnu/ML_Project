{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matteoturnu/ML_Project/blob/main/ML_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "import random\n",
        "from importlib.util import find_spec\n",
        "import json\n",
        "import os\n",
        "import shutil\n",
        "import requests\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn # Contains Required functions and layers\n",
        "import torch.nn.functional as F # For neural network functions:\n",
        "import torch.optim as optim # Contains Optimization function available in PyTorch.\n",
        "project_folder = \"/content/password_strength_classifier\""
      ],
      "metadata": {
        "id": "KykGU56SuABu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creation of useful directories and download of password dictionaries"
      ],
      "metadata": {
        "id": "V8T3qe2zMghF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, dest_folder_name):\n",
        "  local_filename = url.split('/')[-1]\n",
        "  path = os.path.join(\"/{}/{}\".format(dest_folder_name, local_filename))\n",
        "  \"\"\"with requests.get(url, stream=True) as r:\n",
        "      with open(path, 'wb') as f:\n",
        "          shutil.copyfileobj(r.raw, f)\"\"\"\n",
        "\n",
        "  with open(path, 'wb') as f:\n",
        "    f.write(requests.get(url, stream=True).content)\n",
        "\n",
        "  # return local_filename\n",
        "  return path\n",
        "\n",
        "def read_file(filepath):\n",
        "  with open(filepath, errors='replace', encoding='utf-8') as f:\n",
        "    data = {line.split('\\n')[0] for line in f.readlines()}\n",
        "  return data\n",
        "\n",
        "\n",
        "if os.path.exists(project_folder) is False:\n",
        "  dict_dir = project_folder + \"/dictionaries/\"\n",
        "  dataset_dir = project_folder + \"/dataset/\"\n",
        "\n",
        "  os.mkdir(project_folder)\n",
        "  os.mkdir(dataset_dir)\n",
        "\n",
        "  os.mkdir(dict_dir)\n",
        "\n",
        "  f_rockyou = download_file(\n",
        "    \"https://github.com/brannondorsey/naive-hashcat/releases/download/data/rockyou.txt\",\n",
        "    dict_dir)\n",
        "\n",
        "  f_jtr = download_file(\n",
        "      \"https://raw.githubusercontent.com/danielmiessler/SecLists/master/Passwords/Software/john-the-ripper.txt\",\n",
        "      dict_dir)\n",
        "\n",
        "\n",
        "data_rockyou = read_file(f_rockyou)\n",
        "data_jtr = read_file(f_jtr)\n",
        "\n",
        "print(\"\\nRock You\")\n",
        "import itertools\n",
        "print([val for i, val in enumerate(itertools.islice(data_rockyou, 5))])\n",
        "print(\"\\nJohn The Ripper\")\n",
        "print([val for i, val in enumerate(itertools.islice(data_jtr, 5))])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ynOVFhD_5q3r",
        "outputId": "e1d8bd72-3458-499c-96e9-ad37f71fa764"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Rock You\n",
            "['', 'tinelly123', 'belsek100', 'CAES415', '051362916']\n",
            "\n",
            "John The Ripper\n",
            "['soccer', 'xavier', 'christopher', 'farout', 'doogie']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the dataset\n",
        "\n",
        "if find_spec(\"kaggle\") is None:\n",
        "  ! pip install -q kaggle\n",
        "\n",
        "if os.path.isdir(\"/root/.kaggle\") is False:\n",
        "  ! mkdir ~/.kaggle\n",
        "  ! touch \"/root/.kaggle/kaggle.json\"\n",
        "\n",
        "  token = {\"username\":\"matteoturnu\",\"key\":\"79ea644685a3e574038b40e4019b0927\"}\n",
        "  with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
        "    json.dump(token, file)\n",
        "  !chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "  ! kaggle datasets download -d bhavikbb/password-strength-classifier-dataset -p $dataset_dir"
      ],
      "metadata": {
        "id": "y0pIiUJswG7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59d93e7f-6f28-4955-fa56-19b903ae69b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading password-strength-classifier-dataset.zip to /content/password_strength_classifier/dataset\n",
            "\r  0% 0.00/5.01M [00:00<?, ?B/s]\n",
            "\r100% 5.01M/5.01M [00:00<00:00, 111MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# read file\n",
        "\n",
        "file_path = os.path.join(dataset_dir, \"password-strength-classifier-dataset.zip\")\n",
        "\n",
        "pswd_df = pd.read_csv(file_path, on_bad_lines='skip')\n",
        "print(pswd_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jiwHeBuGRgP",
        "outputId": "5156be96-9046-43e1-c937-e036dd6f414d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            password  strength\n",
            "0           kzde5577         1\n",
            "1           kino3434         1\n",
            "2          visi7k1yr         1\n",
            "3           megzy123         1\n",
            "4        lamborghin1         1\n",
            "...              ...       ...\n",
            "669635    10redtux10         1\n",
            "669636     infrared1         1\n",
            "669637  184520socram         1\n",
            "669638     marken22a         1\n",
            "669639      fxx4pw4g         1\n",
            "\n",
            "[669640 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "_VFws5SNT4xt",
        "outputId": "79ffe509-c164-479c-bc8e-cb74218b43ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            password  strength\n",
            "0           kzde5577         1\n",
            "1           kino3434         1\n",
            "2          visi7k1yr         1\n",
            "3           megzy123         1\n",
            "4        lamborghin1         1\n",
            "...              ...       ...\n",
            "669635    10redtux10         1\n",
            "669636     infrared1         1\n",
            "669637  184520socram         1\n",
            "669638     marken22a         1\n",
            "669639      fxx4pw4g         1\n",
            "\n",
            "[669639 rows x 2 columns]\n",
            "[['kzde5577' 1]\n",
            " ['kino3434' 1]\n",
            " ['visi7k1yr' 1]\n",
            " ...\n",
            " ['184520socram' 1]\n",
            " ['marken22a' 1]\n",
            " ['fxx4pw4g' 1]]\n",
            "Len of passwords:  669639\n",
            "Len of UNIQUE passwords:  669639\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'vectorizer = TfidfVectorizer(tokenizer=word_split)\\nX = vectorizer.fit_transform(passwords)\\n\\nprint(vectorizer.get_feature_names_out())'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def word_split(inputs):\n",
        "    character=[]\n",
        "    for i in inputs:\n",
        "        character.append(i)\n",
        "    return character\n",
        "\n",
        "# unique values of strength feature\n",
        "pswd_df['strength'].unique()\n",
        "\n",
        "# number of missing values in dataset\n",
        "pswd_df.isnull().sum()\n",
        "\n",
        "# remove missing values\n",
        "pswd_df.dropna(inplace=True)\n",
        "pswd_df.isnull().sum()\n",
        "\n",
        "print(pswd_df)\n",
        "\n",
        "psw_array = np.array(pswd_df)\n",
        "print(psw_array)\n",
        "\n",
        "# ??? PROBLEM: it is shown that if shuffled then\n",
        "# there are several duplicates of a password\n",
        "#random.shuffle(psw_array)\n",
        "\n",
        "labels = np.array([p[1] for p in psw_array])\n",
        "passwords = np.array([p[0] for p in psw_array])\n",
        "\n",
        "print(\"Len of passwords: \", len(passwords))\n",
        "print(\"Len of UNIQUE passwords: \", len(np.unique(passwords)))\n",
        "\n",
        "\n",
        "\"\"\"vectorizer = TfidfVectorizer(tokenizer=word_split)\n",
        "X = vectorizer.fit_transform(passwords)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manuel - Calculate characters weights"
      ],
      "metadata": {
        "id": "0XE_dLdSqh5e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary containing occurrencies of all the characters in the dataset\n",
        "def calculate_occurrencies(passwords):\n",
        "  weights_dict = dict()\n",
        "  for password in passwords:\n",
        "    for character in password:\n",
        "      if character in weights_dict:\n",
        "        weights_dict[character] += 1\n",
        "      else:\n",
        "        weights_dict[character] = 1\n",
        "  return weights_dict\n",
        "\n",
        "# Converts dictionary values containing occurrencies to weights\n",
        "def calculate_weights(occurrencies_dict):\n",
        "  for key in occurrencies_dict:\n",
        "    occurrencies_dict[key] = 1/occurrencies_dict[key]\n",
        "  return occurrencies_dict\n",
        "\n",
        "weights_dict = calculate_weights(calculate_occurrencies(passwords))\n",
        "print(weights_dict)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9qsx0MWqnJa",
        "outputId": "36ea0c71-4dbc-4136-de20-9adcfe9a9fff"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'k': 7.3281547706287556e-06, 'z': 1.1057176660511506e-05, 'd': 7.674773786042656e-06, 'e': 3.490267389384701e-06, '5': 5.885330225878974e-06, '7': 6.647786951723771e-06, 'i': 3.943310961615811e-06, 'n': 4.889234394786121e-06, 'o': 4.010121546784083e-06, '3': 4.65829105934197e-06, '4': 5.885780542786681e-06, 'v': 1.2305874824641283e-05, 's': 5.169401279943757e-06, '1': 2.593300467572074e-06, 'y': 7.647072318362915e-06, 'r': 5.0159507233000945e-06, 'm': 6.236241292648095e-06, 'g': 7.915525511738725e-06, '2': 3.5612028318684918e-06, 'l': 5.932711189686575e-06, 'a': 2.449347493827644e-06, 'b': 9.556666252544462e-06, 'h': 8.535773426430169e-06, 'A': 2.313690104347424e-05, 'V': 8.035355564483728e-05, 'Y': 4.716313729189266e-05, 'q': 1.813598360507082e-05, 'D': 3.385698808234019e-05, 'E': 4.094333442515558e-05, 'M': 2.4665778698633517e-05, 'Z': 7.958615200955034e-05, 'f': 1.2866038803973032e-05, 'N': 2.8521719289238757e-05, 't': 6.27474602965445e-06, 'u': 6.222233283970282e-06, '6': 6.6518109555326436e-06, 'c': 7.714680265076414e-06, '8': 6.164658015596585e-06, 'w': 1.0280767767736895e-05, '9': 5.0868839783502215e-06, '0': 3.9957165918135754e-06, 'j': 1.0498577442756507e-05, 'W': 7.923302432453847e-05, 'U': 4.7384382107657316e-05, 'I': 4.342350948803682e-05, 'O': 3.543711683617421e-05, 'Q': 3.0766390794695876e-05, 'P': 7.452120128176467e-05, 'p': 8.994018977380042e-06, '@': 0.00018355359765051394, '-': 0.0003178639542275906, 'H': 7.5046904315197e-05, 'x': 1.4390973981119041e-05, '.': 0.0001618646811265782, 'T': 3.35795836131632e-05, '>': 0.010638297872340425, 'G': 7.257420712678714e-05, 'J': 7.45489786789921e-05, '&': 0.0015060240963855422, '?': 0.001996007984031936, '<': 0.00847457627118644, '!': 0.00045829514207149406, 'S': 6.367398917542184e-05, 'R': 6.638783774812455e-05, 'F': 7.720815318097592e-05, 'B': 7.438815740534107e-05, 'K': 7.369739848183359e-05, 'X': 8.048937540244688e-05, 'C': 7.234319612240469e-05, 'L': 6.893223960846487e-05, ';': 0.0027548209366391185, '_': 0.00034164673727365904, '%': 0.0024449877750611247, '±': 0.007518796992481203, '\"': 0.1111111111111111, '~': 0.010752688172043012, '+': 0.001445086705202312, '^': 0.0029585798816568047, '/': 0.001199040767386091, '$': 0.0008771929824561404, ')': 0.0027397260273972603, ' ': 0.0009009009009009009, '(': 0.0031746031746031746, '#': 0.0008278145695364238, 'Ú': 0.038461538461538464, '*': 0.0005327650506126798, '`': 0.07692307692307693, '{': 0.02564102564102564, '}': 0.02702702702702703, '[': 0.006666666666666667, ']': 0.007575757575757576, 'þ': 0.041666666666666664, 'Þ': 0.125, 'Ó': 0.058823529411764705, 'Ô': 0.2, '=': 0.004166666666666667, '\\\\': 0.025, '\\x1c': 0.2, '³': 0.041666666666666664, '¿': 0.2, '\\x16': 0.3333333333333333, 'Ò': 0.5, '·': 0.25, '\\x1e': 0.5, '\\x19': 1.0, '\\x05': 0.3333333333333333, '\\x1b': 0.5, 'Å': 0.07692307692307693, '‚': 1.0, 'Ä': 0.02040816326530612, 'à': 0.5, 'õ': 0.07692307692307693, 'ß': 0.1, '´': 0.5, '«': 1.0, 'ð': 0.2, 'Ð': 0.05, 'å': 0.16666666666666666, 'â': 0.5, '°': 0.08333333333333333, '|': 0.02702702702702703, '\\x7f': 0.5, '²': 0.5, '¾': 0.16666666666666666, 'Ÿ': 0.07692307692307693, '\\x08': 1.0, 'ê': 1.0, 'á': 0.2, '\\x10': 0.25, '\\x17': 0.25, 'º': 0.1, '¡': 0.3333333333333333, '÷': 0.058823529411764705, 'Õ': 0.5, 'í': 0.5, 'ú': 0.16666666666666666, 'µ': 0.25, 'Ý': 0.25, 'Ü': 0.3333333333333333, 'Û': 0.5, 'Ö': 0.5, '×': 1.0, '¨': 0.25, '\\xa0': 0.5, 'æ': 0.3333333333333333, 'è': 1.0, 'ù': 0.5, 'É': 1.0, '\\x06': 0.5, 'Ñ': 0.25, '\\x81': 0.5, '\\x11': 0.5, 'Â': 0.3333333333333333, 'ý': 1.0, '—': 0.5, '›': 0.5, '‹': 1.0, 'œ': 1.0, '™': 1.0, 'ó': 1.0, '¦': 1.0, '\\x0f': 1.0, 'ä': 1.0, 'ï': 1.0, 'Ï': 1.0, 'Ç': 0.14285714285714285, 'ò': 1.0, 'ö': 1.0, '\\x12': 0.25, '\\x8d': 0.5, 'î': 1.0, '¹': 1.0, '¶': 1.0, 'ñ': 1.0, '¼': 0.5, 'Ù': 1.0, '…': 1.0, '\\x13': 1.0, '\\x1d': 1.0, '\\x04': 1.0, '\\x0e': 1.0, '\\x02': 1.0, '¯': 1.0, '\\x01': 1.0, 'Ê': 1.0, 'Æ': 0.5, '‡': 1.0, '¤': 1.0, 'À': 1.0, '¢': 1.0, 'û': 1.0, 'ƒ': 1.0, 'é': 1.0, 'Á': 1.0, '§': 1.0, 'Í': 0.5, 'Ã': 1.0, '»': 1.0, '\\x18': 1.0, '½': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LENGTH feature\n",
        "# lengths = np.array([len(p) for p in passwords]).reshape(-1, 1)\n",
        "lengths = np.array([len(p) for p in passwords])\n",
        "max_len = np.max(lengths)\n",
        "min_len = np.min(lengths)\n",
        "\n",
        "print(\"Lengths shape: \", lengths.shape)\n",
        "\n",
        "print(lengths)\n",
        "print(f\"Max: {max_len} --> {passwords[lengths == max_len]} \\nMin: {min_len} --> {passwords[lengths == min_len]}\")\n",
        "\n",
        "# normalize() from sklearn accept 2D arrays only --> reshape so that we have 1 row (1 \"sample\")\n",
        "# and make sklearn compute the remaining number of columns for us\n",
        "feat_length = normalize(lengths.reshape(1, -1))\n",
        "\n",
        "#feat_length = feat_length.flatten()\n",
        "print(feat_length)\n",
        "\n",
        "\n",
        "# ROCKYOU feature\n",
        "\n",
        "# numpy array of 1 and 0 (0 if found, otherwise is 1)\n",
        "# int() used to convert boolean into number\n",
        "feat_rockyou = np.array([int(p not in data_rockyou) for p in passwords])\n",
        "print(feat_rockyou)\n",
        "\n",
        "# passwords found in rockyou file\n",
        "print(passwords[feat_rockyou == 0])\n",
        "\n",
        "\n",
        "# JTR feature\n",
        "feat_jtr = np.array([int(p not in data_jtr) for p in passwords])\n",
        "print(feat_jtr)\n",
        "print(passwords[feat_jtr == 0])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "awONOEU9HOhF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c24f9225-adb3-4e33-f4e2-0be373b6fa7f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lengths shape:  (669639,)\n",
            "[ 8  8  9 ... 12  9  8]\n",
            "Max: 220 --> ['In0LnUoff8wfayJGqzelyDqg4AMl9gBhgl3T2iZeONzh5gPqTyP8IVLsQ960aZwlZcdSjE1XCi8taVT5dWSB3wNJwMqpzmlSIKh21A8TNxpSJ5nu2hULRgjHZF6fubMkwhjPNRryi0BOyas9zlp6JUsNN0RQ4KRma8satN1JwEOAxlhMgJ7OwgRBbwuqCCiwhdylowbq0xpBsXZbhexgZnq4yOUb'] \n",
            "Min: 1 --> ['M' '9' '1']\n",
            "[[0.00094165 0.00094165 0.00105936 ... 0.00141248 0.00105936 0.00094165]]\n",
            "[1 1 1 ... 1 1 1]\n",
            "['megzy123' 'intel1' 'schalke04' ... 'jenny1989' 'skyline123' 'hattrick9']\n",
            "[1 1 1 ... 1 1 1]\n",
            "['martin1' 'harley1' 'star69' 'dagger1' 'c00per' 'family1' 'michael1'\n",
            " 'ashley1' 'matti1' 'rocket1' 'florida1' 'scott1' 'front242' 'teddy1'\n",
            " 'viper1' 'amanda1' 'phoenix1' 'daniel1' 'rasta1' 'david1' 'rocky1'\n",
            " 'hello123' 'randy1' 'justin1' 'seven7' 'saturn5' 'vampire' 'lucky1'\n",
            " 'master1' 'babylon5' 'xxx123' 'mickey1' 'montana3' '1234qwer' 'happy123'\n",
            " 'cindy1' 'terry1' 'chester1' 'steph1' 'roger1' 'carol1' 'Golden' '654321'\n",
            " 'trustno1' 'pussy1' 'parola' 'simba1' 'peter1' 'william1' 'billy1'\n",
            " 'rambo1' 'Lindsay' 'james1' 'apollo13' 'h2opolo' 'happy1' 'eagle1'\n",
            " 'joker1' 'qqq111' 'catch22' 'qwerty' 'andrew1' 'vincent1' '!@#$%^&'\n",
            " 'ncc1701d' 'jeffrey1' 'andre1' 'wombat1' 'x-files' 'magic1' 'money1'\n",
            " 'smile1' 'kelly1' 'asdf1234' 'Service' 'newyork1' 'scooter1' 'guitar1'\n",
            " 'hello8' '369' 'jordan23' 'tyler1' 'enigma' 'water1' 'alpha1' 'wendy1'\n",
            " 'kevin1' 'julie1' 'mariah1' 'larry1' 'mouse1' 'germany1' 'robert1'\n",
            " '121212' 'jesse1' 'qwerty12' 'soccer1' 'honda1' 'dragon1' 'calvin1'\n",
            " 'hello1' 'abcde' '12345' 'george1' 'tiger2' 'batman1' 'barney1' 'spike1'\n",
            " 'system5' 'route66' 'number9' 'glider1' 'nirvana1' 'keith1' 'susan1'\n",
            " 'karen1' '123456' 'nexus6' 'heather1' 'mustang1' 'charlie1' 'joshua'\n",
            " 'angel1' 'chris1' 'victor1' 'piano1' 'a1b2c3d4' 'pedro1' 'jesus1'\n",
            " 'abcd1234' 'chris123' 'hawkeye1' 'zxcvbnm' 'bubba1' 'maria1' 'sarah1'\n",
            " 'monkey1' 'student2' 'christ1' '1' 'andrea1' 'shadow1' 'porsche911'\n",
            " '1234' 'secret' 'jason1' 'ernie1' 'molly1' 'apple1' 'mulder1' 'colt45'\n",
            " 'chelsea1' 'richard1' 'apple2' 'sunny1' 'ricardo1' 'sherry' 'steven1'\n",
            " '123123' 'rabbit1' '!@#$%^' '123' 'alice1' 'wayne1' '000000' 'steve1'\n",
            " 'gustavo' 'skipper1' 'ncc1701e' 'Knight' 'admin1' 'safety1' 'fuckyou'\n",
            " '111111']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manuel - Password structure feature"
      ],
      "metadata": {
        "id": "uxIR4HNJgG7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define macros\n",
        "numbers = 0\n",
        "lower_case = 1\n",
        "upper_case = 2\n",
        "special_char = 3\n",
        "\n",
        "# Counts numbers, lowercases, uppercases and other characters in a password\n",
        "def calculate_password_structure(passwords):\n",
        "  passwords_structure = []\n",
        "  for password in passwords:\n",
        "    counts = np.array([0, 0, 0, 0])\n",
        "    for character in password:\n",
        "      if character.isnumeric():\n",
        "        counts[numbers] += 1\n",
        "      elif character.islower():\n",
        "        counts[lower_case] += 1\n",
        "      elif character.isupper():\n",
        "        counts[upper_case] += 1\n",
        "      else:\n",
        "        counts[special_char] += 1\n",
        "\n",
        "    passwords_structure.append(counts / len(password))\n",
        "  return np.array(passwords_structure)\n",
        "\n",
        "feat_structure = calculate_password_structure(passwords)\n",
        "for i in range(20):\n",
        "  print(passwords[i], feat_structure[i])"
      ],
      "metadata": {
        "id": "wLptS-t0gAEK",
        "outputId": "af32d2b9-4135-4013-d10b-20e45078eb15",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kzde5577 [0.5 0.5 0.  0. ]\n",
            "kino3434 [0.5 0.5 0.  0. ]\n",
            "visi7k1yr [0.22222222 0.77777778 0.         0.        ]\n",
            "megzy123 [0.375 0.625 0.    0.   ]\n",
            "lamborghin1 [0.09090909 0.90909091 0.         0.        ]\n",
            "AVYq1lDE4MgAZfNt [0.125  0.3125 0.5625 0.    ]\n",
            "u6c8vhow [0.25 0.75 0.   0.  ]\n",
            "v1118714 [0.875 0.125 0.    0.   ]\n",
            "universe2908 [0.33333333 0.66666667 0.         0.        ]\n",
            "as326159 [0.75 0.25 0.   0.  ]\n",
            "asv5o9yu [0.25 0.75 0.   0.  ]\n",
            "612035180tok [0.75 0.25 0.   0.  ]\n",
            "jytifok873 [0.3 0.7 0.  0. ]\n",
            "WUt9IZzE0OQ7PkNE [0.1875 0.1875 0.625  0.    ]\n",
            "jerusalem393 [0.25 0.75 0.   0.  ]\n",
            "g067057895 [0.9 0.1 0.  0. ]\n",
            "52558000aaa [0.72727273 0.27272727 0.         0.        ]\n",
            "idofo673 [0.375 0.625 0.    0.   ]\n",
            "6975038lp [0.77777778 0.22222222 0.         0.        ]\n",
            "sbl571017 [0.66666667 0.33333333 0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manuel - Password score feature by characters appearance frequency"
      ],
      "metadata": {
        "id": "Klkyyk59omsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate passwords score with character weights\n",
        "def calculate_password_scores(passwords):\n",
        "  scores = []\n",
        "  for password in passwords:\n",
        "    score = 0\n",
        "    for character in password:\n",
        "      # If weight does not exists in the dictionary, it is a very rare character so 1.001 points are given\n",
        "      try:\n",
        "        score += weights_dict[character]\n",
        "      except:\n",
        "        score += 1.001\n",
        "    scores.append(score)\n",
        "\n",
        "  return np.array(scores)\n",
        "\n",
        "feat_scores = calculate_password_scores(passwords)\n",
        "for i in range(20):\n",
        "  print(passwords[i], feat_scores[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3vr_4C-o06P",
        "outputId": "648e24e7-d7d7-4515-935f-29a01d8822c5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kzde5577 5.4616606961773106e-05\n",
            "kino3434 4.125896487807207e-05\n",
            "visi7k1yr 5.459416325940427e-05\n",
            "megzy123 4.7159077531428475e-05\n",
            "lamborghin1 6.107818326093385e-05\n",
            "AVYq1lDE4MgAZfNt 0.00044096855367907917\n",
            "u6c8vhow 6.188592008576835e-05\n",
            "v1118714 4.137730220503662e-05\n",
            "universe2908 6.333500166465563e-05\n",
            "as326159 3.605556829231577e-05\n",
            "asv5o9yu 4.8776264951759156e-05\n",
            "612035180tok 5.7712349554057255e-05\n",
            "jytifok873 7.003875790043788e-05\n",
            "WUt9IZzE0OQ7PkNE 0.0005411506299646499\n",
            "jerusalem393 6.290846358193651e-05\n",
            "g067057895 5.8876546000050805e-05\n",
            "52558000aaa 4.671704378202566e-05\n",
            "idofo673 5.046225561179805e-05\n",
            "6975038lp 5.401720794530435e-05\n",
            "sbl571017 4.902200037845903e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the feature vector\n",
        "# Currently we are not including \"feat_score\"\n",
        "\n",
        "# divide \"feat_structure\" in its sub-features since hstack() needs the same\n",
        "# dimension for every array\n",
        "\n",
        "def create_feature_vector(features_list):\n",
        "  # 4 features in the list\n",
        "\n",
        "\n",
        "  for feature in features_list:\n",
        "    if len(feature.shape) != 1: # it's 2-d feature_structure or feat_length\n",
        "      if abs(feature.shape[1]) > 1: # it's the 2-d feature_structure --> decompose it to 4 different sub-features\n",
        "\n",
        "\n",
        "\n",
        "  features_vector = np.hstack(feature)\n",
        "  return feature_vector\n",
        "\n",
        "print(\"\\nFeature length: \", feat_length)\n",
        "print(\"\\nFeature rockyou: \", feat_rockyou)\n",
        "print(\"\\nFeature jtr: \", feat_jtr)\n",
        "print(\"\\nFeature structure --> numbers: \", feat_structure[:, 0])\n",
        "print(\"\\nFeature structure --> lowercase: \", feat_structure[:, 1])\n",
        "print(\"\\nFeature structure --> uppercase: \", feat_structure[:, 2])\n",
        "print(\"\\nFeature structure --> special: \", feat_structure[:, 3])\n",
        "\n",
        "print(\"feature shape: \", len(feat_length.shape))\n",
        "\n",
        "\n",
        "feature_vector = np.hstack((feat_length, feat_rockyou, feat_jtr, feat_structure[:, 0],\n",
        "                            feat_structure[:, 1], feat_structure[:, 2], feat_structure[:, 3]))\n",
        "print(feature_vector)\n",
        "print(feature_vector.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9OzjdbbivBUF",
        "outputId": "3ae18d52-223a-4852-cdaf-be5c2e809014",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Feature length:  [[0.00094165 0.00094165 0.00105936 ... 0.00141248 0.00105936 0.00094165]]\n",
            "\n",
            "Feature rockyou:  [1 1 1 ... 1 1 1]\n",
            "\n",
            "Feature jtr:  [1 1 1 ... 1 1 1]\n",
            "\n",
            "Feature structure --> numbers:  [0.5        0.5        0.22222222 ... 0.5        0.22222222 0.25      ]\n",
            "\n",
            "Feature structure --> lowercase:  [0.5        0.5        0.77777778 ... 0.5        0.77777778 0.75      ]\n",
            "\n",
            "Feature structure --> uppercase:  [0. 0. 0. ... 0. 0. 0.]\n",
            "\n",
            "Feature structure --> special:  [0. 0. 0. ... 0. 0. 0.]\n",
            "feature shape:  2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-1221c3dc1ed3>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m feature_vector = np.hstack((feat_length, feat_rockyou, feat_jtr, feat_structure[:, 0],\n\u001b[0m\u001b[1;32m     29\u001b[0m                             feat_structure[:, 1], feat_structure[:, 2], feat_structure[:, 3]))\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/shape_base.py\u001b[0m in \u001b[0;36mhstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Manuel - Neural Network"
      ],
      "metadata": {
        "id": "P2Ovy96LylJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "\n",
        "  def __init__(self, n_input, n_output):\n",
        "    super().__init__()\n",
        "    self.n_input = n_input\n",
        "    self.n_output = n_output\n",
        "    self.mid_n = int((n_input + n_output) / 2)\n",
        "\n",
        "    # Define Layers:\n",
        "    self.l1 = nn.Linear(self.n_input, self.mid_n) # layer 1\n",
        "    self.l2 = nn.Linear(self.mid_n, self.n_output) # layer 2\n",
        "    self.l3 = nn.Linear(self.n_output, self.n_output) # layer 3\n",
        "\n",
        "    # Define Activation functions:\n",
        "    self.relu = nn.ReLU()\n",
        "    self.softmax = nn.LogSoftmax(dim = 1)\n",
        "\n",
        "    # Weights initialization\n",
        "    nn.init.kaiming_normal_(self.l1.weight, mode='fan_in', nonlinearity='relu') # Using HE because more optimized for ReLU activated layers\n",
        "    nn.init.zeros_(self.l1.bias)\n",
        "    nn.init.kaiming_normal_(self.l2.weight, mode='fan_in', nonlinearity='relu')\n",
        "    nn.init.zeros_(self.l2.bias)\n",
        "    nn.init.normal_(self.l3.weight) # Using normal distribution for LogSoftMax activated layer\n",
        "    nn.init.normal_(self.l3.bias)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "    '''\n",
        "    Layers: 3\n",
        "    Activation Functions:\n",
        "    RELU for first two layers\n",
        "    Log Softmax for last layer\n",
        "    '''\n",
        "    x = self.l1(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.l2(x)\n",
        "    x = self.relu(x)\n",
        "    x = self.l3(x)\n",
        "    x = self.softmax(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "  def train_model(self, tr_loader, n_epochs, criterion, optimizer):\n",
        "    # losses --> {[*idx_first_epoch*]: loss_1, [*idx_second_epoch*]: loss_2, ...}\n",
        "    losses = {}\n",
        "    for e in range(n_epochs):\n",
        "      for features, labels in tr_loader:\n",
        "        optimizer.zero_grad() # set optimizer gradients to zero:\n",
        "        output = self(features) # Intial output\n",
        "        loss = criterion(output, labels.long()) # Loss Caluclation\n",
        "        loss.backward() # Pass loss function gradients to pervious layers:\n",
        "        optimizer.step() # Update Weights\n",
        "        losses[e] = loss.item()\n",
        "\n",
        "    return losses\n",
        "\n",
        "\n",
        "  def test_model(self, ts_loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for features, labels in ts_loader:\n",
        "      outputs = self(features)\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum()\n",
        "\n",
        "    return correct / total\n",
        "\n",
        "\n",
        "\n",
        "# Define macros.\n",
        "number_of_features = 8 # Rockyou, johntheripper , password len, numbers/len, lowercases/len, uppercases/len, special characters/len, password score\n",
        "number_of_outputs = 3 # Unsecure, intermediate, secure\n",
        "\n",
        "NN = NeuralNetwork(number_of_features, number_of_outputs)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.Adam(NN.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "4FDFyMMQypbx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}